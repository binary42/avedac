#!/bin/bash
#
# Name:runAVEDworkflow-condor
#
# This script creates and launches a Condor dagman to process an 
# .AVI, .MOV, or .MPG video clip, or a compressed sequence of still
# frames (tgz, tar.gz, or tar files acceptable)
#
# It creates a dag to describe the processing sequence and executes it.
# 
# Usage:  runAVEDworkflow-condor -i < filename.AVI , filename.MOV > 
#
# This script creates and executes a dag to process EITS video either
# on the AVED Beowulf cluster or an available workstation, depending
# on whether the "-p" option is specified. See the "-p" option below
# for more information
#
# Copyright (c) MBARI 2010
# Author: D. Cline
#
# exit on error- this will exit this bash script when any command exits with
# a non-zero exit code
set -e 
###################################################################################
# Print usage
print_usage()
{
  echo "  "
  echo "  "
  echo -e "\033[1m USAGE:  runAVEDworkflow-condor [OPTION] -i [filename.AVI,MOV,MPG,tar,tgz,tar.gz]  \033[0m"
  echo "  "
  echo "  "
  echo "OPTION"
  echo "  "
  echo -e "\033[1m -d \033[0m"
  echo "  "
  echo "      Create the dag description only for later execution - do not execute " 
  echo "  "
  echo "      (Example:  runAVEDworkflow-condor -d mydagfile.dag -i filename.AVI or filename.MOV)"
  echo " "
  echo "  "
  echo -e "\033[1m -p \033[0m"
  echo "  "
  echo "      Use parallel AVED code for procesing " 
  echo "  "
  echo "      (Example:  runAVEDworkflow-condor -p -d mydagfile.dag -i filename.AVI or filename.MOV)"
  echo " "
  echo -e "\033[1m -m \033[0m"
  echo "  "
  echo "      Use video mask to mask unwanted area during processing " 
  echo "  "
  echo "      (Example:  runAVEDworkflow-condor -p -d mydagfile.dag -i filename.AVI -v mymask.jpg)"
  echo " "
  echo -e "\033[1m -p \033[0m"
  echo "  "
  echo "      Use alternative URL base for input/output URL define (default uses the hostname)"
  echo "  "
  echo "      (Example:  runAVEDworkflow-condor -u "http://eits" -d mydagfile.dag -i filename.AVI -v mymask.jpg)"
  echo -e ""
}
###################################################################################
if test $# -lt 1 
then print_usage
exit 1
fi

# Initialize variables
create_dag_only=0
useparallel=0
input_file=""
video_mask=
use_pmbarivision=0

# Format the dag filename
dag=AVEDworkflow.dag

# Initialize the working directory to this directory
# This should be a location where there is enough disk space to put the 
# processed output
output_dir=$PWD

# Used to define the output and input URLs
base_url="file://`hostname``pwd`"

# Check arguments
while getopts d:i:m:u:p option 
do
  case $option in   
   i)  input_file="$OPTARG";;
   m)  video_mask="$OPTARG"
       D=$(dirname $video_mask)
       video_mask_abs_path="`cd $D && pwd `";;
   d)  dag="$OPTARG"
       create_dag_only=1;;
   u)  base_url="$OPTARG";;
   p)  use_pmbarivision=1;;
   *)  echo "Unimplemented option chosen."
       echo "  "
       print_usage;;
  esac
done

# Must have a file argument so check and 
if [ ! "$input_file"  ]; then
    print_usage
    exit 1
fi

# Factor out the file stem from the input file
# e.g. /home/dcline/test.mov file stem is test
# This is used to create a working scratch directory 
# to process the file in
# get extension; everything after last'.'
ext=${input_file##*.} 
basefile=$(basename $input_file)
filestem=${basefile%.*} 
D=$(dirname $input_file)
abspath="`cd $D && pwd `"

# If is zipped tar, then adjust the basefile
# and the input_file_stem because here we have
# a special case of two '.' in the filename
# This assumes that the file is formatted <filename>.tar.gz
if [ "$ext" == "gz" ]; then
    filestem=${input_file%%.*}
fi 


# Only check the file is not creating a dag - 
# may be referencing a file that is not yet created by a calling dag
if [ $create_dag_only == 0 ]; then
    if [ -e $abspath/$basefile ]; then
	echo "Found $input_file"
    else
	echo "Error $input_file does not exist"
	exit 1
    fi
fi

# Only create directory and log file dir if actually running this
# and *not* creating a dag only
if [ $create_dag_only == 0 ]; then
    
   # If no condor_log directory create it and all parent directories
    if [ -d $output_dir/$filestem/condor_log ]; then
	echo "Found $output_dir/$filestem/condor_log"
    else    
	mkdir -p $output_dir/$filestem/condor_log	
	chmod a+rwx $output_dir
	chmod a+rwx $output_dir/$filestem
	chmod a+rwx $output_dir/$filestem/$condor_log
    fi  
  
    # Move into the output_dir directory
    pushd $output_dir/$filestem;

    # Copy the input file to this directory
    cp -f $abspath/$basefile .
fi

# Define the condor job files and
# copy all of the condor job files to the output folder.
# This assumes the job files are in ${HOME)/aved/scripts
if [ $use_pmbarivision == 1  ];then
    jobprocess=job.prunclip.condor
else    
    jobprocess=job.runclip.condor
fi

# Check for OS and use .bat file if Cygwin submission
if [ `uname | grep Linux` ]; then
    postfilecheck=postscript_checkfile
else  # assume this is Cygwin
    postfilecheck=postscript_checkfile.bat
fi

jobfinalizeaved=job.finalizeaved.condor

# This assumes the user installs the scripts in
# their home directory.  Running them outside
# the home directory is problematic whe submitting
# from a Windows host
scripts_dir=${HOME}/aved/scripts

# Copy all the job scripts needed 
cp $scripts_dir/$jobprocess $scripts_dir/$jobfinalizeaved $scripts_dir/$postfilecheck .

# If video mask is defined, change the job files to handle
# the videomask file
if [ "$video_mask" ]; then
  video_mask_base=$(basename $video_mask)
# If the video file doesn't exists in this directory, copy it
if [ ! -e $video_mask_abs_path/$video_mask_base ]; then
  cp $video_mask_abs_path/$video_mask_base .
fi
  sed -i -e "s/arguments = \" /arguments = \" -m $video_mask_base /g" $jobprocess
  sed -i -e "/^transfer_input_files/{p;s/.*/$video_mask_base,\\\/;}" $jobprocess
fi

# Defines output folder the results are in.
# This is what is sent to the owner of the PRUNCLIP job upon completion
output_url="$base_url"

# Defines the input URL of the processed video clip
input_url="$base_url/$basefile"

# If MBARIVISION_OPTIONS
# is not set, set it because
# it is referenced in the Condor jobs files
if [ ! "$MBARIVISION_OPTIONS" ]; then
    export MBARIVISION_OPTIONS=""
fi

# Add parallel specific jobs, variables, and order the dag for parallel execution 
if [ $use_pmbarivision == 1  ];then
cat > $dag <<_ACEOF 
Job PRUNCLIP $jobprocess
Job FINALAVED $jobfinalizeaved

VARS PRUNCLIP input_file="$basefile" input_url="$input_url" processed_results_url="$output_url" pvision_worker_file="$filestem.workers"

Parent PRUNCLIP Child FINALAVED

ABORT-DAG-ON PRUNCLIP 2
RETRY PRUNCLIP 1 UNLESS-EXIT 2

DOT $dag.dot  UPDATE OVERWRITE 
Script POST PRUNCLIP $postfilecheck $filestem.events.xml
_ACEOF

else # Add non-parallel specific jobs, variables, and order the dag correctly 
cat > $dag <<_ACEOF 
Job RUNCLIP $jobprocess
Job FINALAVED $jobfinalizeaved

VARS FINALAVED directory="$filestem" 
VARS RUNCLIP input_file="$basefile" input_url="$input_url" processed_results_url="$output_url"

Parent RUNCLIP Child FINALAVED

DOT $dag.dot  UPDATE OVERWRITE 
Script POST RUNCLIP $postfilecheck $filestem.events.xml
_ACEOF
fi

# Make the dag read and writeable bu users, group, and others
chmod ugo+rw $dag

if [ $create_dag_only == 1 ]; then
   condor_submit_dag -force -no_submit -notification Error -UseDagDir $dag
else
   condor_submit_dag -force -notification Error  $dag 
fi

exit 0
